{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":11677052,"sourceType":"datasetVersion","datasetId":7328834}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Roberta-aegyptustranslit-classifier","metadata":{}},{"cell_type":"markdown","source":"## Overview\nA fine-tuned RoBERTa-base model for classifying Ancient Egyptian transliterations into their respective historical time periods ('Predynastic & Early Dynastic', 'Old Kingdom & First Intermediate', 'Middle Kingdom & Second Intermediate', 'New Kingdom & Third Intermediate', 'Late Period & Greco-Roman Egypt').\n## Training Results\n\n| Metric | Value |\n|--------|-------|\n| **F1 Score** | ~0.562 |\n| **Weighted F1** | ~0.567 |\n| **Validation Loss** | ~1.5295 |\n| **Epochs** | 20 |\n| **Learning Rate** | 2e-5 |\n| **Batch Size** | 64 |\n\n## Per-class F1 scores:\n- **Predynastic & Early Dynastic:** F1 = 0.576\n- **Old Kingdom & First Intermediate:** F1 = 0.432\n- **Middle Kingdom & Second Intermediate:** F1 = 0.468\n- **New Kingdom & Third Intermediate:** F1 = 0.713\n- **Late Period & Greco-Roman Egypt:** F1 = 0.608\n\n## Intended Use & Limitations\n\nThis model is designed for **historical text classification** and intended for exploratory research and as a performance baseline. \nCurrent constraints include:  \n- **Data limitations**: ~10k balanced samples may not represent all orthographic variations.  \n- **Period bias**: Middle Kingdom classification (F1=0.47) underperforms due to:  \n  - Orthographic overlap with neighboring periods  \n- **Best practices**: Always verify critical classifications with primary sources.  \n\n**Roadmap**:  \n- Expand to ccorpus samples (balanced & unbalanced)\n\n## Data Used For Training\n\nThesaurus Linguae Aegyptiae, Late Egyptian sentences, corpus v19, premium, https://huggingface.co/datasets/thesaurus-linguae-aegyptiae/tla-late_egyptian-v19-premium, v1.0, 1/19/2025 ed. by Tonio Sebastian Richter & Daniel A. Werning on behalf of the Berlin-Brandenburgische Akademie der Wissenschaften and Hans-Werner Fischer-Elfert & Peter Dils on behalf of the Sächsische Akademie der Wissenschaften zu Leipzig.\nThesaurus Linguae Aegyptiae, Original Earlier Egyptian sentences, corpus v18, premium, https://huggingface.co/datasets/thesaurus-linguae-aegyptiae/tla-Earlier_Egyptian_original-v18-premium, v1.1, 2/16/2024 ed. by Tonio Sebastian Richter & Daniel A. Werning on behalf of the Berlin-Brandenburgische Akademie der Wissenschaften and Hans-Werner Fischer-Elfert & Peter Dils on behalf of the Sächsische Akademie der Wissenschaften zu Leipzig.\nThesaurus Linguae Aegyptiae, Demotic sentences, corpus v18, premium https://huggingface.co/datasets/thesaurus-linguae-aegyptiae/tla-demotic-v18-premium, v1.1, 2/16/2024 ed. by Tonio Sebastian Richter & Daniel A. Werning on behalf of the Berlin-Brandenburgische Akademie der Wissenschaften and Hans-Werner Fischer-Elfert & Peter Dils on behalf of the Sächsische Akademie der Wissenschaften zu Leipzig.\n## Usage\n```python\n# Using pipline\nfrom transformers import pipeline\nclassifier = pipeline(\"text-classification\", model=\"RamzyBakir/roberta-aegyptustranslit-classifier\")\nclassifier(\"bn-ꞽw n rmṯ-ḫm ꞽn ꜥn pꜣ nty ḫꜣꜥ pꜣ myṱ r-ḏbꜣ swg\")\n# Load model directly\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nmodel = AutoModelForSequenceClassification.from_pretrained(\"RamzyBakir/roberta-aegyptustranslit-classifier\")\ntokenizer = AutoTokenizer.from_pretrained(\"RamzyBakir/roberta-aegyptustranslit-classifier\")\n","metadata":{}},{"cell_type":"code","source":"from datasets import load_dataset\n\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\n\nimport numpy as np\nfrom transformers import DataCollatorWithPadding","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-05-07T11:00:54.725519Z","iopub.execute_input":"2025-05-07T11:00:54.725781Z","iopub.status.idle":"2025-05-07T11:01:22.710310Z","shell.execute_reply.started":"2025-05-07T11:00:54.725760Z","shell.execute_reply":"2025-05-07T11:01:22.709704Z"}},"outputs":[{"name":"stderr","text":"2025-05-07 11:01:09.989972: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746615670.195755      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746615670.250481      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# Data Loading and Preparation","metadata":{}},{"cell_type":"code","source":"def label_dates(df):\n    # Define period boundaries\n    periods = [\n        {\"name\": \"Predynastic & Early Dynastic\", \"start\": -4300, \"end\": -2675},\n        {\"name\": \"Old Kingdom & First Intermediate\", \"start\": -2675, \"end\": -1980},\n        {\"name\": \"Middle Kingdom & Second Intermediate\", \"start\": -1980, \"end\": -1539},\n        {\"name\": \"New Kingdom & Third Intermediate\", \"start\": -1539, \"end\": -656},\n        {\"name\": \"Late Period & Greco-Roman Egypt\", \"start\": -664, \"end\": 642}\n    ]\n\n    # Initialize the datelabel column with \"Unknown\"\n    df['datelabel'] = \"Unknown\"\n\n    # Process each row individually\n    for i in df.index:\n        for period in periods:\n            if df.at[i, 'dateNotBefore'] <= period[\"end\"] and df.at[i, 'dateNotAfter'] >= period[\"start\"]:\n                df.at[i, 'datelabel'] = period[\"name\"]\n                break  # Take the first matching period and stop checking\n\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T11:01:22.711635Z","iopub.execute_input":"2025-05-07T11:01:22.712229Z","iopub.status.idle":"2025-05-07T11:01:22.717620Z","shell.execute_reply.started":"2025-05-07T11:01:22.712208Z","shell.execute_reply":"2025-05-07T11:01:22.716896Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nimport requests\nimport json\nfrom pandas import json_normalize\n\nearly = pd.read_json(\"hf://datasets/thesaurus-linguae-aegyptiae/tla-Earlier_Egyptian_original-v18-premium/train.jsonl\", lines=True)\nearly = label_dates(early)\nlate = pd.read_json(\"hf://datasets/thesaurus-linguae-aegyptiae/tla-late_egyptian-v19-premium/train.jsonl\", lines=True)\nlate = label_dates(late)\n\n# URL for the Hugging Face Datasets API\nurl = \"https://huggingface.co/datasets/thesaurus-linguae-aegyptiae/tla-demotic-v18-premium/raw/main/train.jsonl\"\n\n# Make the request\nresponse = requests.get(url)\n\n# Check if the request was successful\nif response.status_code == 200:\n    # Split the text by lines because it's a JSONL file\n    lines = response.text.strip().split('\\n')\n\n    # Parse each line as JSON\n    data = [json.loads(line) for line in lines]\n\n    # Now each item is a normal JSON object you can work with\n    dfs = [json_normalize(item) for item in data]\n\n    # If you want a single DataFrame\n    demotic = pd.concat(dfs, ignore_index=True)\ndemotic['dateNotBefore'] = demotic['dateNotBefore'].replace('', 0)\ndemotic['dateNotAfter'] = demotic['dateNotAfter'].replace('', 0)\ndemotic['dateNotBefore'] = demotic['dateNotBefore'].astype(int)\ndemotic['dateNotAfter'] = demotic['dateNotAfter'].astype(int)\ndemotic = label_dates(demotic)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T11:01:22.718316Z","iopub.execute_input":"2025-05-07T11:01:22.718523Z","iopub.status.idle":"2025-05-07T11:01:29.717321Z","shell.execute_reply.started":"2025-05-07T11:01:22.718507Z","shell.execute_reply":"2025-05-07T11:01:29.716625Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"merged_corpus_df = pd.concat([\n    early[[\"transliteration\", \"datelabel\"]],\n    late[[\"transliteration\", \"datelabel\"]],\n    demotic[[\"transliteration\", \"datelabel\"]]],\n    ignore_index=True)\nmerged_corpus_df.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T11:01:29.718699Z","iopub.execute_input":"2025-05-07T11:01:29.718942Z","iopub.status.idle":"2025-05-07T11:01:29.733399Z","shell.execute_reply.started":"2025-05-07T11:01:29.718923Z","shell.execute_reply":"2025-05-07T11:01:29.732547Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(29762, 2)"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"period_mapping = {\n    \"Predynastic & Early Dynastic\": 0,\n    \"Old Kingdom & First Intermediate\": 1,\n    \"Middle Kingdom & Second Intermediate\": 2,\n    \"New Kingdom & Third Intermediate\": 3,\n    \"Late Period & Greco-Roman Egypt\": 4\n}\nmerged_corpus_df[\"period_label\"] = merged_corpus_df[\"datelabel\"].map(period_mapping)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T11:01:29.734369Z","iopub.execute_input":"2025-05-07T11:01:29.734687Z","iopub.status.idle":"2025-05-07T11:01:29.745413Z","shell.execute_reply.started":"2025-05-07T11:01:29.734662Z","shell.execute_reply":"2025-05-07T11:01:29.744481Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"merged_corpus_df = merged_corpus_df.drop(\"datelabel\",axis=1)\nmerged_corpus_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T11:01:29.746282Z","iopub.execute_input":"2025-05-07T11:01:29.746746Z","iopub.status.idle":"2025-05-07T11:01:29.771402Z","shell.execute_reply.started":"2025-05-07T11:01:29.746719Z","shell.execute_reply":"2025-05-07T11:01:29.770711Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"                                     transliteration  period_label\n0                                     nḏ (w)di̯ r =s             2\n1                                        n ṯw ꞽm =sn             1\n2  ḫꜣ m tʾ ḥnq.t kꜣ(.PL) ꜣpd(.PL) n ꞽmꜣḫ ꞽm.ꞽ-rʾ-...             2\n3                                                ꜥḥꜥ             1\n4  (w)sꞽr wnꞽs m n =k ꞽr.t-ḥr.w ꞽꜥb n =k s(ꞽ) ꞽr ...             1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>transliteration</th>\n      <th>period_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>nḏ (w)di̯ r =s</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>n ṯw ꞽm =sn</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ḫꜣ m tʾ ḥnq.t kꜣ(.PL) ꜣpd(.PL) n ꞽmꜣḫ ꞽm.ꞽ-rʾ-...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ꜥḥꜥ</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>(w)sꞽr wnꞽs m n =k ꞽr.t-ḥr.w ꞽꜥb n =k s(ꞽ) ꞽr ...</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"id2label = {\n    0: \"Predynastic & Early Dynastic\",\n    1: \"Old Kingdom & First Intermediate\",\n    2: \"Middle Kingdom & Second Intermediate\",\n    3: \"New Kingdom & Third Intermediate\",\n    4: \"Late Period & Greco-Roman Egypt\"\n}\n\nlabel2id = {\n    \"Predynastic & Early Dynastic\": 0,\n    \"Old Kingdom & First Intermediate\": 1,\n    \"Middle Kingdom & Second Intermediate\": 2,\n    \"New Kingdom & Third Intermediate\": 3,\n    \"Late Period & Greco-Roman Egypt\": 4\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T11:01:29.772152Z","iopub.execute_input":"2025-05-07T11:01:29.772361Z","iopub.status.idle":"2025-05-07T11:01:29.776516Z","shell.execute_reply.started":"2025-05-07T11:01:29.772345Z","shell.execute_reply":"2025-05-07T11:01:29.775732Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# Model and Tokenizer loading","metadata":{}},{"cell_type":"code","source":"# Load model directly\nfrom transformers import RobertaTokenizerFast, RobertaForSequenceClassification\n\nmodel_path = \"FacebookAI/roberta-base\"\n\nmodel = RobertaForSequenceClassification.from_pretrained(model_path, \n                                                           num_labels=5, \n                                                           id2label=id2label, \n                                                           label2id=label2id,)\ntokenizer = RobertaTokenizerFast.from_pretrained(\"FacebookAI/roberta-base\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T11:02:12.979841Z","iopub.execute_input":"2025-05-07T11:02:12.980569Z","iopub.status.idle":"2025-05-07T11:02:16.205569Z","shell.execute_reply.started":"2025-05-07T11:02:12.980536Z","shell.execute_reply":"2025-05-07T11:02:16.205010Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4aa6bb188e164b8681d2cbdc53828ce2"}},"metadata":{}},{"name":"stderr","text":"Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ecef168041548ec8962432d87f8f9f0"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d1273d0d1bd34aaeb9b9e91dad2adcb4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8003ef77179448bf86d4c5c27cfe3676"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f5ce06f7197427f92d142518dadbdfa"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f04de4f9a9364d1792aebcaf972e80bc"}},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"with open(\"text.txt\", \"r\") as f:\n    text = f.read()\n    print(len(text))  # Number of characters","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T09:00:20.895859Z","iopub.execute_input":"2025-05-07T09:00:20.896595Z","iopub.status.idle":"2025-05-07T09:00:20.920092Z","shell.execute_reply.started":"2025-05-07T09:00:20.896571Z","shell.execute_reply":"2025-05-07T09:00:20.919479Z"}},"outputs":[{"name":"stdout","text":"984771\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"# Data Transformation, Labeling and Balancing","metadata":{}},{"cell_type":"code","source":"num_labels = []\nfor i in merged_corpus_df[\"period_label\"].unique():\n    val = merged_corpus_df[merged_corpus_df[\"period_label\"] == i].shape[0]\n    num_labels.append(val)\n    print(id2label[i],\"=\",val)\n\ndef create_balanced_dataset(df):\n    # Randomly sample \"ham\" instances to match the number of min label instances\n    early_subset = df[df[\"period_label\"] == 0].sample(min(num_labels), random_state=123)\n    old_first_subset = df[df[\"period_label\"] == 1].sample(min(num_labels), random_state=123)\n    middle_second_subset = df[df[\"period_label\"] == 2].sample(min(num_labels), random_state=123)\n    new_third_subset = df[df[\"period_label\"] == 3].sample(min(num_labels), random_state=123)\n    late_subset = df[df[\"period_label\"] == 4].sample(min(num_labels), random_state=123)\n    # Combine subsets\n    balanced_df = pd.concat([\n        early_subset[[\"transliteration\", \"period_label\"]],\n        old_first_subset[[\"transliteration\", \"period_label\"]],\n        middle_second_subset[[\"transliteration\", \"period_label\"]],\n        new_third_subset[[\"transliteration\", \"period_label\"]],\n        late_subset[[\"transliteration\", \"period_label\"]]],\n        ignore_index=True)\n\n    return balanced_df\n\nbalanced_df = create_balanced_dataset(merged_corpus_df)\nprint(balanced_df[\"period_label\"].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T11:02:19.867811Z","iopub.execute_input":"2025-05-07T11:02:19.868697Z","iopub.status.idle":"2025-05-07T11:02:19.896573Z","shell.execute_reply.started":"2025-05-07T11:02:19.868669Z","shell.execute_reply":"2025-05-07T11:02:19.896027Z"}},"outputs":[{"name":"stdout","text":"Middle Kingdom & Second Intermediate = 3476\nOld Kingdom & First Intermediate = 6945\nPredynastic & Early Dynastic = 2375\nNew Kingdom & Third Intermediate = 3740\nLate Period & Greco-Roman Egypt = 13226\nperiod_label\n0    2375\n1    2375\n2    2375\n3    2375\n4    2375\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"print(merged_corpus_df[\"period_label\"].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T11:02:21.273464Z","iopub.execute_input":"2025-05-07T11:02:21.274204Z","iopub.status.idle":"2025-05-07T11:02:21.278838Z","shell.execute_reply.started":"2025-05-07T11:02:21.274178Z","shell.execute_reply":"2025-05-07T11:02:21.278210Z"}},"outputs":[{"name":"stdout","text":"period_label\n4    13226\n1     6945\n3     3740\n2     3476\n0     2375\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"def random_split(df, train_frac, validation_frac):\n    # Shuffle the entire DataFrame\n    df = df.sample(frac=1, random_state=123).reset_index(drop=True)\n\n    # Calculate split indices\n    train_end = int(len(df) * train_frac)\n    validation_end = train_end + int(len(df) * validation_frac)\n\n    # Split the DataFrame\n    train_df = df[:train_end]\n    validation_df = df[train_end:validation_end]\n    test_df = df[validation_end:]\n\n    return train_df, validation_df, test_df\n\nutrain_df, uvalidation_df, utest_df = random_split(merged_corpus_df, 0.8, 0.1)\nutrain_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T11:02:24.583332Z","iopub.execute_input":"2025-05-07T11:02:24.583924Z","iopub.status.idle":"2025-05-07T11:02:24.599620Z","shell.execute_reply.started":"2025-05-07T11:02:24.583899Z","shell.execute_reply":"2025-05-07T11:02:24.598859Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"                                     transliteration  period_label\n0  pꜣ nkt nty-ꞽw =k ꞽw dy(.t) s n =s nkt ꜥn wḫꜣ =...             4\n1     r nꜣ rd.w n pꜣ sẖ-ḥr sẖ ẖr-rd.wy pꜣ sẖ n-rn =f             4\n2                                  pꜣ wr-ꞽꜣbṱ pꜣ-qll             4\n3    tw =f ꞽn =w wꜥ šrṱ n šs-n-nsw mtw =f ꞽ.ꞽr-ḥr =f             4\n4                        zꜣ =k pw n(.ꞽ) ḏ.t =k n ḏ.t             1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>transliteration</th>\n      <th>period_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>pꜣ nkt nty-ꞽw =k ꞽw dy(.t) s n =s nkt ꜥn wḫꜣ =...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>r nꜣ rd.w n pꜣ sẖ-ḥr sẖ ẖr-rd.wy pꜣ sẖ n-rn =f</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>pꜣ wr-ꞽꜣbṱ pꜣ-qll</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>tw =f ꞽn =w wꜥ šrṱ n šs-n-nsw mtw =f ꞽ.ꞽr-ḥr =f</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>zꜣ =k pw n(.ꞽ) ḏ.t =k n ḏ.t</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"btrain_df, bvalidation_df, btest_df = random_split(balanced_df, 0.8, 0.1)\nbtrain_df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T11:02:26.111518Z","iopub.execute_input":"2025-05-07T11:02:26.111791Z","iopub.status.idle":"2025-05-07T11:02:26.121734Z","shell.execute_reply.started":"2025-05-07T11:02:26.111769Z","shell.execute_reply":"2025-05-07T11:02:26.121092Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                                     transliteration  period_label\n0  ta-mn ta pꜣ-ꞽgš sꜣ pꜣ-ꜥlꜥl pꜣ h̭ꜥ(m) mw.t =s t...             4\n1                ꞽr =f wꜥb n nꜣ rpy.w n pꜣ tš-n-nw.t             4\n2            ḥtp-ḏi̯ nswt ḥtp-ḏi̯ ꞽnp.w ḫnt.ꞽ-zḥ-nṯr             1\n3                                 ḏd.ꞽn nm.tꞽ-nḫt pn             2\n4                                         ḥmw.tꞽ wḥꜥ             0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>transliteration</th>\n      <th>period_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>ta-mn ta pꜣ-ꞽgš sꜣ pꜣ-ꜥlꜥl pꜣ h̭ꜥ(m) mw.t =s t...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>ꞽr =f wꜥb n nꜣ rpy.w n pꜣ tš-n-nw.t</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ḥtp-ḏi̯ nswt ḥtp-ḏi̯ ꞽnp.w ḫnt.ꞽ-zḥ-nṯr</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ḏd.ꞽn nm.tꞽ-nḫt pn</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>ḥmw.tꞽ wḥꜥ</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"def preprocess_function(examples):\n    return tokenizer(examples[\"transliteration\"], truncation=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T11:02:40.816567Z","iopub.execute_input":"2025-05-07T11:02:40.816834Z","iopub.status.idle":"2025-05-07T11:02:40.820540Z","shell.execute_reply.started":"2025-05-07T11:02:40.816814Z","shell.execute_reply":"2025-05-07T11:02:40.819897Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"from datasets import Dataset\n\n# unbalanced\nutrain_dataset = Dataset.from_pandas(utrain_df)\nuval_dataset = Dataset.from_pandas(uvalidation_df)\nutest_dataset = Dataset.from_pandas(utest_df)\n# balanced\nbtrain_dataset = Dataset.from_pandas(btrain_df)\nbval_dataset = Dataset.from_pandas(bvalidation_df)\nbtest_dataset = Dataset.from_pandas(btest_df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T11:02:27.687219Z","iopub.execute_input":"2025-05-07T11:02:27.687655Z","iopub.status.idle":"2025-05-07T11:02:27.740743Z","shell.execute_reply.started":"2025-05-07T11:02:27.687633Z","shell.execute_reply":"2025-05-07T11:02:27.739903Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"utrain_dataset = utrain_dataset.map(preprocess_function, batched=True)\nuval_dataset = uval_dataset.map(preprocess_function, batched=True)\nutest_dataset = utest_dataset.map(preprocess_function, batched=True)\n\nbtrain_dataset = btrain_dataset.map(preprocess_function, batched=True)\nbval_dataset = bval_dataset.map(preprocess_function, batched=True)\nbtest_dataset = btest_dataset.map(preprocess_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T11:02:43.050515Z","iopub.execute_input":"2025-05-07T11:02:43.050788Z","iopub.status.idle":"2025-05-07T11:02:45.352181Z","shell.execute_reply.started":"2025-05-07T11:02:43.050768Z","shell.execute_reply":"2025-05-07T11:02:45.351405Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/23809 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0b005ed45a414a30a645c6f084a8de98"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2976 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"54ccbb22367541728210c6675e0c8180"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2977 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"142433f56c704326be959e669ec02b73"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/9500 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1c84f11cc4a04ab296f0914dd02ff9c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1187 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e87e35251c354b39b4cd220e7bc938fb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1188 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eeec91738587456797d8debb7e5c70a2"}},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"utrain_dataset = utrain_dataset.rename_column(\"period_label\", \"labels\")\nuval_dataset = uval_dataset.rename_column(\"period_label\", \"labels\")\nutest_dataset = utest_dataset.rename_column(\"period_label\", \"labels\")\nbtrain_dataset = btrain_dataset.rename_column(\"period_label\", \"labels\")\nbval_dataset = bval_dataset.rename_column(\"period_label\", \"labels\")\nbtest_dataset = btest_dataset.rename_column(\"period_label\", \"labels\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T11:02:45.353463Z","iopub.execute_input":"2025-05-07T11:02:45.354059Z","iopub.status.idle":"2025-05-07T11:02:45.364372Z","shell.execute_reply.started":"2025-05-07T11:02:45.354039Z","shell.execute_reply":"2025-05-07T11:02:45.363482Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# freeze base model parameters\nfor name, param in model.base_model.named_parameters():\n    param.requires_grad = False\n\n# unfreeze base model pooling layers\nfor name, param in model.base_model.named_parameters():\n    if \"pooler\" in name:\n        param.requires_grad = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T11:02:47.190522Z","iopub.execute_input":"2025-05-07T11:02:47.191094Z","iopub.status.idle":"2025-05-07T11:02:47.195645Z","shell.execute_reply.started":"2025-05-07T11:02:47.191070Z","shell.execute_reply":"2025-05-07T11:02:47.195083Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments\nfrom sklearn.metrics import classification_report,accuracy_score, f1_score\n\nlabel_names = ['Predynastic & Early Dynastic', 'Old Kingdom & First Intermediate', 'Middle Kingdom & Second Intermediate', 'New Kingdom & Third Intermediate', 'Late Period & Greco-Roman Egypt']\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = logits.argmax(axis=-1)\n    \n    accuracy = accuracy_score(labels, predictions)\n    f1 = f1_score(labels, predictions, average=\"macro\")\n    report = classification_report(\n        labels, predictions, target_names=label_names, output_dict=True, zero_division=0\n    )\n\n    print(\"\\nPer-class F1 scores:\")\n    for label in label_names:\n        print(f\"{label}: F1 = {report[label]['f1-score']:.3f}\")\n    \n    return {\n        \"accuracy\": accuracy,\n        \"f1\": f1,  \n        \"weighted_f1\": f1_score(labels, predictions, average=\"weighted\")\n    }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T11:02:51.226252Z","iopub.execute_input":"2025-05-07T11:02:51.226871Z","iopub.status.idle":"2025-05-07T11:02:51.232280Z","shell.execute_reply.started":"2025-05-07T11:02:51.226846Z","shell.execute_reply":"2025-05-07T11:02:51.231495Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"data_collator = DataCollatorWithPadding(tokenizer=tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T11:02:57.479355Z","iopub.execute_input":"2025-05-07T11:02:57.480010Z","iopub.status.idle":"2025-05-07T11:02:57.483583Z","shell.execute_reply.started":"2025-05-07T11:02:57.479955Z","shell.execute_reply":"2025-05-07T11:02:57.482814Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T11:02:58.833728Z","iopub.execute_input":"2025-05-07T11:02:58.834196Z","iopub.status.idle":"2025-05-07T11:02:58.839806Z","shell.execute_reply.started":"2025-05-07T11:02:58.834172Z","shell.execute_reply":"2025-05-07T11:02:58.839145Z"}},"outputs":[{"execution_count":25,"output_type":"execute_result","data":{"text/plain":"RobertaForSequenceClassification(\n  (roberta): RobertaModel(\n    (embeddings): RobertaEmbeddings(\n      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n      (position_embeddings): Embedding(514, 768, padding_idx=1)\n      (token_type_embeddings): Embedding(1, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (encoder): RobertaEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x RobertaLayer(\n          (attention): RobertaAttention(\n            (self): RobertaSdpaSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): RobertaSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): RobertaIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): RobertaOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n  )\n  (classifier): RobertaClassificationHead(\n    (dense): Linear(in_features=768, out_features=768, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n    (out_proj): Linear(in_features=768, out_features=5, bias=True)\n  )\n)"},"metadata":{}}],"execution_count":25},{"cell_type":"markdown","source":"# Model Training","metadata":{}},{"cell_type":"markdown","source":"## 1- Model Fine-tunning on Balanced Data","metadata":{}},{"cell_type":"code","source":"# hyperparameters\nlr = 2e-5\nbatch_size = 64\nnum_epochs = 20\n\ntraining_args = TrainingArguments(\n    report_to = \"none\",\n    output_dir=\"roberta-aeTranslit-classifier_optimized-new-tokenizer-balanced\",\n    learning_rate=lr, \n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    num_train_epochs=num_epochs,\n    logging_strategy=\"epoch\",\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    weight_decay=0.01,\n    adam_beta1=0.9,\n    adam_beta2=0.999,\n    adam_epsilon=1e-8,\n    lr_scheduler_type=\"linear\",\n    warmup_ratio=0.1,   \n    metric_for_best_model=\"weighted_f1\",\n    save_total_limit=10,\n    load_best_model_at_end=True,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T11:03:12.861700Z","iopub.execute_input":"2025-05-07T11:03:12.862001Z","iopub.status.idle":"2025-05-07T11:03:12.897020Z","shell.execute_reply.started":"2025-05-07T11:03:12.861977Z","shell.execute_reply":"2025-05-07T11:03:12.896453Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"trainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=btrain_dataset,\n    eval_dataset=bval_dataset,\n    processing_class=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T11:03:24.140714Z","iopub.execute_input":"2025-05-07T11:03:24.141023Z","iopub.status.idle":"2025-05-07T11:25:47.589985Z","shell.execute_reply.started":"2025-05-07T11:03:24.141000Z","shell.execute_reply":"2025-05-07T11:25:47.589352Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1500/1500 22:20, Epoch 20/20]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n      <th>Weighted F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.612700</td>\n      <td>1.611171</td>\n      <td>0.213142</td>\n      <td>0.119119</td>\n      <td>0.111414</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.606000</td>\n      <td>1.602151</td>\n      <td>0.374895</td>\n      <td>0.272582</td>\n      <td>0.268411</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.598400</td>\n      <td>1.594909</td>\n      <td>0.306655</td>\n      <td>0.248548</td>\n      <td>0.244632</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.591800</td>\n      <td>1.587975</td>\n      <td>0.419545</td>\n      <td>0.325245</td>\n      <td>0.321192</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>1.583300</td>\n      <td>1.581635</td>\n      <td>0.526537</td>\n      <td>0.513853</td>\n      <td>0.516040</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>1.577100</td>\n      <td>1.574976</td>\n      <td>0.525695</td>\n      <td>0.496804</td>\n      <td>0.502083</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>1.569000</td>\n      <td>1.569198</td>\n      <td>0.502949</td>\n      <td>0.464219</td>\n      <td>0.462967</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>1.563500</td>\n      <td>1.564449</td>\n      <td>0.501264</td>\n      <td>0.460828</td>\n      <td>0.460325</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>1.557700</td>\n      <td>1.558656</td>\n      <td>0.513058</td>\n      <td>0.477067</td>\n      <td>0.478311</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>1.552300</td>\n      <td>1.554013</td>\n      <td>0.518955</td>\n      <td>0.495399</td>\n      <td>0.497647</td>\n    </tr>\n    <tr>\n      <td>11</td>\n      <td>1.546900</td>\n      <td>1.549460</td>\n      <td>0.532435</td>\n      <td>0.512440</td>\n      <td>0.514943</td>\n    </tr>\n    <tr>\n      <td>12</td>\n      <td>1.543200</td>\n      <td>1.545420</td>\n      <td>0.536647</td>\n      <td>0.519433</td>\n      <td>0.522239</td>\n    </tr>\n    <tr>\n      <td>13</td>\n      <td>1.539000</td>\n      <td>1.541699</td>\n      <td>0.536647</td>\n      <td>0.513805</td>\n      <td>0.516776</td>\n    </tr>\n    <tr>\n      <td>14</td>\n      <td>1.535100</td>\n      <td>1.538792</td>\n      <td>0.548441</td>\n      <td>0.533860</td>\n      <td>0.537665</td>\n    </tr>\n    <tr>\n      <td>15</td>\n      <td>1.530100</td>\n      <td>1.535792</td>\n      <td>0.565291</td>\n      <td>0.555395</td>\n      <td>0.560072</td>\n    </tr>\n    <tr>\n      <td>16</td>\n      <td>1.529300</td>\n      <td>1.533585</td>\n      <td>0.557709</td>\n      <td>0.544997</td>\n      <td>0.549285</td>\n    </tr>\n    <tr>\n      <td>17</td>\n      <td>1.527600</td>\n      <td>1.531698</td>\n      <td>0.572030</td>\n      <td>0.562503</td>\n      <td>0.567107</td>\n    </tr>\n    <tr>\n      <td>18</td>\n      <td>1.525000</td>\n      <td>1.530509</td>\n      <td>0.561921</td>\n      <td>0.550029</td>\n      <td>0.554346</td>\n    </tr>\n    <tr>\n      <td>19</td>\n      <td>1.524000</td>\n      <td>1.529752</td>\n      <td>0.565291</td>\n      <td>0.554748</td>\n      <td>0.559442</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.523100</td>\n      <td>1.529585</td>\n      <td>0.568660</td>\n      <td>0.559614</td>\n      <td>0.563826</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"\nPer-class F1 scores:\nPredynastic & Early Dynastic: F1 = 0.273\nOld Kingdom & First Intermediate: F1 = 0.000\nMiddle Kingdom & Second Intermediate: F1 = 0.322\nNew Kingdom & Third Intermediate: F1 = 0.000\nLate Period & Greco-Roman Egypt: F1 = 0.000\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nPer-class F1 scores:\nPredynastic & Early Dynastic: F1 = 0.606\nOld Kingdom & First Intermediate: F1 = 0.000\nMiddle Kingdom & Second Intermediate: F1 = 0.281\nNew Kingdom & Third Intermediate: F1 = 0.476\nLate Period & Greco-Roman Egypt: F1 = 0.000\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nPer-class F1 scores:\nPredynastic & Early Dynastic: F1 = 0.409\nOld Kingdom & First Intermediate: F1 = 0.008\nMiddle Kingdom & Second Intermediate: F1 = 0.353\nNew Kingdom & Third Intermediate: F1 = 0.472\nLate Period & Greco-Roman Egypt: F1 = 0.000\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nPer-class F1 scores:\nPredynastic & Early Dynastic: F1 = 0.593\nOld Kingdom & First Intermediate: F1 = 0.088\nMiddle Kingdom & Second Intermediate: F1 = 0.354\nNew Kingdom & Third Intermediate: F1 = 0.560\nLate Period & Greco-Roman Egypt: F1 = 0.031\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nPer-class F1 scores:\nPredynastic & Early Dynastic: F1 = 0.590\nOld Kingdom & First Intermediate: F1 = 0.287\nMiddle Kingdom & Second Intermediate: F1 = 0.495\nNew Kingdom & Third Intermediate: F1 = 0.667\nLate Period & Greco-Roman Egypt: F1 = 0.531\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nPer-class F1 scores:\nPredynastic & Early Dynastic: F1 = 0.574\nOld Kingdom & First Intermediate: F1 = 0.386\nMiddle Kingdom & Second Intermediate: F1 = 0.322\nNew Kingdom & Third Intermediate: F1 = 0.639\nLate Period & Greco-Roman Egypt: F1 = 0.563\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nPer-class F1 scores:\nPredynastic & Early Dynastic: F1 = 0.591\nOld Kingdom & First Intermediate: F1 = 0.283\nMiddle Kingdom & Second Intermediate: F1 = 0.438\nNew Kingdom & Third Intermediate: F1 = 0.667\nLate Period & Greco-Roman Egypt: F1 = 0.407\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nPer-class F1 scores:\nPredynastic & Early Dynastic: F1 = 0.571\nOld Kingdom & First Intermediate: F1 = 0.415\nMiddle Kingdom & Second Intermediate: F1 = 0.394\nNew Kingdom & Third Intermediate: F1 = 0.668\nLate Period & Greco-Roman Egypt: F1 = 0.429\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nPer-class F1 scores:\nPredynastic & Early Dynastic: F1 = 0.570\nOld Kingdom & First Intermediate: F1 = 0.361\nMiddle Kingdom & Second Intermediate: F1 = 0.454\nNew Kingdom & Third Intermediate: F1 = 0.684\nLate Period & Greco-Roman Egypt: F1 = 0.493\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nPer-class F1 scores:\nPredynastic & Early Dynastic: F1 = 0.576\nOld Kingdom & First Intermediate: F1 = 0.385\nMiddle Kingdom & Second Intermediate: F1 = 0.444\nNew Kingdom & Third Intermediate: F1 = 0.691\nLate Period & Greco-Roman Egypt: F1 = 0.501\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nPer-class F1 scores:\nPredynastic & Early Dynastic: F1 = 0.576\nOld Kingdom & First Intermediate: F1 = 0.322\nMiddle Kingdom & Second Intermediate: F1 = 0.460\nNew Kingdom & Third Intermediate: F1 = 0.686\nLate Period & Greco-Roman Egypt: F1 = 0.525\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nPer-class F1 scores:\nPredynastic & Early Dynastic: F1 = 0.574\nOld Kingdom & First Intermediate: F1 = 0.332\nMiddle Kingdom & Second Intermediate: F1 = 0.473\nNew Kingdom & Third Intermediate: F1 = 0.730\nLate Period & Greco-Roman Egypt: F1 = 0.561\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nPer-class F1 scores:\nPredynastic & Early Dynastic: F1 = 0.578\nOld Kingdom & First Intermediate: F1 = 0.392\nMiddle Kingdom & Second Intermediate: F1 = 0.463\nNew Kingdom & Third Intermediate: F1 = 0.728\nLate Period & Greco-Roman Egypt: F1 = 0.617\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nPer-class F1 scores:\nPredynastic & Early Dynastic: F1 = 0.584\nOld Kingdom & First Intermediate: F1 = 0.362\nMiddle Kingdom & Second Intermediate: F1 = 0.462\nNew Kingdom & Third Intermediate: F1 = 0.726\nLate Period & Greco-Roman Egypt: F1 = 0.591\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nPer-class F1 scores:\nPredynastic & Early Dynastic: F1 = 0.587\nOld Kingdom & First Intermediate: F1 = 0.408\nMiddle Kingdom & Second Intermediate: F1 = 0.467\nNew Kingdom & Third Intermediate: F1 = 0.726\nLate Period & Greco-Roman Egypt: F1 = 0.625\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nPer-class F1 scores:\nPredynastic & Early Dynastic: F1 = 0.580\nOld Kingdom & First Intermediate: F1 = 0.404\nMiddle Kingdom & Second Intermediate: F1 = 0.454\nNew Kingdom & Third Intermediate: F1 = 0.714\nLate Period & Greco-Roman Egypt: F1 = 0.597\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nPer-class F1 scores:\nPredynastic & Early Dynastic: F1 = 0.578\nOld Kingdom & First Intermediate: F1 = 0.428\nMiddle Kingdom & Second Intermediate: F1 = 0.444\nNew Kingdom & Third Intermediate: F1 = 0.708\nLate Period & Greco-Roman Egypt: F1 = 0.616\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nPer-class F1 scores:\nPredynastic & Early Dynastic: F1 = 0.576\nOld Kingdom & First Intermediate: F1 = 0.432\nMiddle Kingdom & Second Intermediate: F1 = 0.468\nNew Kingdom & Third Intermediate: F1 = 0.713\nLate Period & Greco-Roman Egypt: F1 = 0.608\n","output_type":"stream"},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1500, training_loss=1.5567582244873046, metrics={'train_runtime': 1342.6631, 'train_samples_per_second': 141.51, 'train_steps_per_second': 1.117, 'total_flos': 1.6795908173372832e+16, 'train_loss': 1.5567582244873046, 'epoch': 20.0})"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"print(f\"Best model checkpoint: {trainer.state.best_model_checkpoint}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T11:26:23.851389Z","iopub.execute_input":"2025-05-07T11:26:23.851676Z","iopub.status.idle":"2025-05-07T11:26:23.856214Z","shell.execute_reply.started":"2025-05-07T11:26:23.851655Z","shell.execute_reply":"2025-05-07T11:26:23.855488Z"}},"outputs":[{"name":"stdout","text":"Best model checkpoint: roberta-aeTranslit-classifier_optimized-new-tokenizer-balanced/checkpoint-1275\n","output_type":"stream"}],"execution_count":29},{"cell_type":"code","source":"import os\nsave_dir = \"/kaggle/working/roberta-aegyptustranslit-classifier-balanced\"\nos.makedirs(save_dir, exist_ok=True)\n\ntrainer.save_model(save_dir)\ntokenizer.save_pretrained(save_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T11:26:33.698947Z","iopub.execute_input":"2025-05-07T11:26:33.699254Z","iopub.status.idle":"2025-05-07T11:26:34.953458Z","shell.execute_reply.started":"2025-05-07T11:26:33.699234Z","shell.execute_reply":"2025-05-07T11:26:34.952721Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/roberta-aegyptustranslit-classifier-balanced/tokenizer_config.json',\n '/kaggle/working/roberta-aegyptustranslit-classifier-balanced/special_tokens_map.json',\n '/kaggle/working/roberta-aegyptustranslit-classifier-balanced/vocab.json',\n '/kaggle/working/roberta-aegyptustranslit-classifier-balanced/merges.txt',\n '/kaggle/working/roberta-aegyptustranslit-classifier-balanced/added_tokens.json',\n '/kaggle/working/roberta-aegyptustranslit-classifier-balanced/tokenizer.json')"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"from transformers import pipeline\n\nclassifier = pipeline(\"text-classification\", model=\"/kaggle/working/roberta-aegyptustranslit-classifier-balanced\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T11:26:39.313899Z","iopub.execute_input":"2025-05-07T11:26:39.314258Z","iopub.status.idle":"2025-05-07T11:26:40.099703Z","shell.execute_reply.started":"2025-05-07T11:26:39.314237Z","shell.execute_reply":"2025-05-07T11:26:40.099132Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"# Creating Copy of balanced test data\nbtest_df_copy = btest_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T11:27:02.525800Z","iopub.execute_input":"2025-05-07T11:27:02.526169Z","iopub.status.idle":"2025-05-07T11:27:02.529872Z","shell.execute_reply.started":"2025-05-07T11:27:02.526145Z","shell.execute_reply":"2025-05-07T11:27:02.529163Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"# Predicting the balanced test data classes\nbpreds = []\nfor cell in btest_df_copy[\"transliteration\"]:\n    bpreds.append(classifier(cell)[0]['label'])\n\nbtest_df_copy[\"preds\"] = bpreds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T11:27:17.719202Z","iopub.execute_input":"2025-05-07T11:27:17.719463Z","iopub.status.idle":"2025-05-07T11:27:27.807873Z","shell.execute_reply.started":"2025-05-07T11:27:17.719445Z","shell.execute_reply":"2025-05-07T11:27:27.807142Z"}},"outputs":[{"name":"stderr","text":"You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n","output_type":"stream"}],"execution_count":33},{"cell_type":"code","source":"# Mapping predicted class id to label\nbtest_df_copy['period_label_text'] = btest_df_copy['period_label'].map(id2label)\n\n# Calculate accuracy\ncorrect_predictions = (btest_df_copy['period_label_text'] == btest_df_copy['preds']).sum()\ntotal_predictions = len(btest_df_copy)\naccuracy = (correct_predictions / total_predictions) * 100\n\n# Display results\nprint(f\"Total samples: {total_predictions}\")\nprint(f\"Correct predictions: {correct_predictions}\")\nprint(f\"Accuracy: {accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T11:28:12.727560Z","iopub.execute_input":"2025-05-07T11:28:12.728303Z","iopub.status.idle":"2025-05-07T11:28:12.738151Z","shell.execute_reply.started":"2025-05-07T11:28:12.728274Z","shell.execute_reply":"2025-05-07T11:28:12.737500Z"}},"outputs":[{"name":"stdout","text":"Total samples: 1188\nCorrect predictions: 679\nAccuracy: 57.15%\n","output_type":"stream"}],"execution_count":34},{"cell_type":"markdown","source":"## 2- Model Fine-tunning on Unalanced and Weighted Data","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.nn import CrossEntropyLoss\nfrom sklearn.utils.class_weight import compute_class_weight\n\n# Compute class weights (sklearn)\nclass_weights = compute_class_weight(\n    \"balanced\", \n    classes=np.unique(utrain_df[\"period_label\"]), \n    y=utrain_df[\"period_label\"]\n)\nclass_weights = torch.tensor(class_weights, dtype=torch.float32).to('cuda')\nclass_weights","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T11:33:29.026910Z","iopub.execute_input":"2025-05-07T11:33:29.027543Z","iopub.status.idle":"2025-05-07T11:33:29.232481Z","shell.execute_reply.started":"2025-05-07T11:33:29.027520Z","shell.execute_reply":"2025-05-07T11:33:29.231819Z"}},"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"tensor([2.5115, 0.8517, 1.6910, 1.5985, 0.4523], device='cuda:0')"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"# Add to Trainer\nclass WeightedTrainer(Trainer): \n    def compute_loss(self, model, inputs, return_outputs=False,num_items_in_batch=None):\n        labels = inputs.get(\"labels\")\n        # forward pass\n        outputs = model(**inputs)\n        logits = outputs.get('logits')\n        # compute custom loss\n        loss_fct = CrossEntropyLoss(weight=class_weights)\n        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1)).to('cuda')\n        return (loss, outputs) if return_outputs else loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T11:33:30.561552Z","iopub.execute_input":"2025-05-07T11:33:30.562120Z","iopub.status.idle":"2025-05-07T11:33:30.566599Z","shell.execute_reply.started":"2025-05-07T11:33:30.562093Z","shell.execute_reply":"2025-05-07T11:33:30.565907Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"# hyperparameters\nlr = 2e-5\nbatch_size = 64\nnum_epochs = 10\n\ntraining_args2 = TrainingArguments(\n    report_to = \"none\",\n    output_dir=\"roberta-aeTranslit-classifier_optimized-unbalanced\",\n    learning_rate=lr, \n    per_device_train_batch_size=batch_size,\n    per_device_eval_batch_size=batch_size,\n    num_train_epochs=num_epochs,\n    logging_strategy=\"epoch\",\n    eval_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    weight_decay=0.01,\n    adam_beta1=0.9,\n    adam_beta2=0.999,\n    adam_epsilon=1e-8,\n    lr_scheduler_type=\"linear\",\n    warmup_ratio=0.1,   \n    metric_for_best_model=\"weighted_f1\",\n    save_total_limit=10,\n    load_best_model_at_end=True,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T11:33:51.744839Z","iopub.execute_input":"2025-05-07T11:33:51.745423Z","iopub.status.idle":"2025-05-07T11:33:51.779119Z","shell.execute_reply.started":"2025-05-07T11:33:51.745397Z","shell.execute_reply":"2025-05-07T11:33:51.778383Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"training_args2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T11:33:52.655667Z","iopub.execute_input":"2025-05-07T11:33:52.655935Z","iopub.status.idle":"2025-05-07T11:33:52.661642Z","shell.execute_reply.started":"2025-05-07T11:33:52.655913Z","shell.execute_reply":"2025-05-07T11:33:52.660870Z"}},"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"TrainingArguments(\n_n_gpu=2,\naccelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\nadafactor=False,\nadam_beta1=0.9,\nadam_beta2=0.999,\nadam_epsilon=1e-08,\nauto_find_batch_size=False,\naverage_tokens_across_devices=False,\nbatch_eval_metrics=False,\nbf16=False,\nbf16_full_eval=False,\ndata_seed=None,\ndataloader_drop_last=False,\ndataloader_num_workers=0,\ndataloader_persistent_workers=False,\ndataloader_pin_memory=True,\ndataloader_prefetch_factor=None,\nddp_backend=None,\nddp_broadcast_buffers=None,\nddp_bucket_cap_mb=None,\nddp_find_unused_parameters=None,\nddp_timeout=1800,\ndebug=[],\ndeepspeed=None,\ndisable_tqdm=False,\ndo_eval=True,\ndo_predict=False,\ndo_train=False,\neval_accumulation_steps=None,\neval_delay=0,\neval_do_concat_batches=True,\neval_on_start=False,\neval_steps=None,\neval_strategy=IntervalStrategy.EPOCH,\neval_use_gather_object=False,\nfp16=False,\nfp16_backend=auto,\nfp16_full_eval=False,\nfp16_opt_level=O1,\nfsdp=[],\nfsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\nfsdp_min_num_params=0,\nfsdp_transformer_layer_cls_to_wrap=None,\nfull_determinism=False,\ngradient_accumulation_steps=1,\ngradient_checkpointing=False,\ngradient_checkpointing_kwargs=None,\ngreater_is_better=True,\ngroup_by_length=False,\nhalf_precision_backend=auto,\nhub_always_push=False,\nhub_model_id=None,\nhub_private_repo=None,\nhub_strategy=HubStrategy.EVERY_SAVE,\nhub_token=<HUB_TOKEN>,\nignore_data_skip=False,\ninclude_for_metrics=[],\ninclude_inputs_for_metrics=False,\ninclude_num_input_tokens_seen=False,\ninclude_tokens_per_second=False,\njit_mode_eval=False,\nlabel_names=None,\nlabel_smoothing_factor=0.0,\nlearning_rate=2e-05,\nlength_column_name=length,\nload_best_model_at_end=True,\nlocal_rank=0,\nlog_level=passive,\nlog_level_replica=warning,\nlog_on_each_node=True,\nlogging_dir=roberta-aeTranslit-classifier_optimized-unbalanced/runs/May07_11-33-51_d90d140240e7,\nlogging_first_step=False,\nlogging_nan_inf_filter=True,\nlogging_steps=500,\nlogging_strategy=IntervalStrategy.EPOCH,\nlr_scheduler_kwargs={},\nlr_scheduler_type=SchedulerType.LINEAR,\nmax_grad_norm=1.0,\nmax_steps=-1,\nmetric_for_best_model=weighted_f1,\nmp_parameters=,\nneftune_noise_alpha=None,\nno_cuda=False,\nnum_train_epochs=10,\noptim=OptimizerNames.ADAMW_TORCH,\noptim_args=None,\noptim_target_modules=None,\noutput_dir=roberta-aeTranslit-classifier_optimized-unbalanced,\noverwrite_output_dir=False,\npast_index=-1,\nper_device_eval_batch_size=64,\nper_device_train_batch_size=64,\nprediction_loss_only=False,\npush_to_hub=False,\npush_to_hub_model_id=None,\npush_to_hub_organization=None,\npush_to_hub_token=<PUSH_TO_HUB_TOKEN>,\nray_scope=last,\nremove_unused_columns=True,\nreport_to=[],\nrestore_callback_states_from_checkpoint=False,\nresume_from_checkpoint=None,\nrun_name=roberta-aeTranslit-classifier_optimized-unbalanced,\nsave_on_each_node=False,\nsave_only_model=False,\nsave_safetensors=True,\nsave_steps=500,\nsave_strategy=SaveStrategy.EPOCH,\nsave_total_limit=10,\nseed=42,\nskip_memory_metrics=True,\ntf32=None,\ntorch_compile=False,\ntorch_compile_backend=None,\ntorch_compile_mode=None,\ntorch_empty_cache_steps=None,\ntorchdynamo=None,\ntp_size=0,\ntpu_metrics_debug=False,\ntpu_num_cores=None,\nuse_cpu=False,\nuse_ipex=False,\nuse_legacy_prediction_loop=False,\nuse_liger_kernel=False,\nuse_mps_device=False,\nwarmup_ratio=0.1,\nwarmup_steps=0,\nweight_decay=0.01,\n)"},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"trainer2 = WeightedTrainer(\n    model=model,\n    args=training_args2,\n    train_dataset=utrain_dataset,\n    eval_dataset=bval_dataset,\n    processing_class=tokenizer,\n    data_collator=data_collator,\n    compute_metrics=compute_metrics,\n)\n\ntrainer2.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T11:34:02.197188Z","iopub.execute_input":"2025-05-07T11:34:02.197475Z","iopub.status.idle":"2025-05-07T12:01:40.406378Z","shell.execute_reply.started":"2025-05-07T11:34:02.197454Z","shell.execute_reply":"2025-05-07T12:01:40.405639Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1870' max='1870' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1870/1870 27:36, Epoch 10/10]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n      <th>F1</th>\n      <th>Weighted F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.523000</td>\n      <td>1.493049</td>\n      <td>0.573715</td>\n      <td>0.559713</td>\n      <td>0.565764</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>1.507400</td>\n      <td>1.477557</td>\n      <td>0.570345</td>\n      <td>0.559061</td>\n      <td>0.566600</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>1.488800</td>\n      <td>1.445254</td>\n      <td>0.576243</td>\n      <td>0.555274</td>\n      <td>0.562858</td>\n    </tr>\n    <tr>\n      <td>4</td>\n      <td>1.473500</td>\n      <td>1.430102</td>\n      <td>0.583825</td>\n      <td>0.570361</td>\n      <td>0.577322</td>\n    </tr>\n    <tr>\n      <td>5</td>\n      <td>1.458700</td>\n      <td>1.405639</td>\n      <td>0.566133</td>\n      <td>0.538545</td>\n      <td>0.545861</td>\n    </tr>\n    <tr>\n      <td>6</td>\n      <td>1.449000</td>\n      <td>1.401579</td>\n      <td>0.580455</td>\n      <td>0.555526</td>\n      <td>0.563785</td>\n    </tr>\n    <tr>\n      <td>7</td>\n      <td>1.435800</td>\n      <td>1.386338</td>\n      <td>0.583825</td>\n      <td>0.568242</td>\n      <td>0.575027</td>\n    </tr>\n    <tr>\n      <td>8</td>\n      <td>1.432400</td>\n      <td>1.381745</td>\n      <td>0.582140</td>\n      <td>0.559159</td>\n      <td>0.567132</td>\n    </tr>\n    <tr>\n      <td>9</td>\n      <td>1.428900</td>\n      <td>1.377783</td>\n      <td>0.583825</td>\n      <td>0.561070</td>\n      <td>0.568925</td>\n    </tr>\n    <tr>\n      <td>10</td>\n      <td>1.424100</td>\n      <td>1.374511</td>\n      <td>0.581297</td>\n      <td>0.557174</td>\n      <td>0.565235</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stdout","text":"\nPer-class F1 scores:\nPredynastic & Early Dynastic: F1 = 0.575\nOld Kingdom & First Intermediate: F1 = 0.359\nMiddle Kingdom & Second Intermediate: F1 = 0.450\nNew Kingdom & Third Intermediate: F1 = 0.735\nLate Period & Greco-Roman Egypt: F1 = 0.679\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nPer-class F1 scores:\nPredynastic & Early Dynastic: F1 = 0.579\nOld Kingdom & First Intermediate: F1 = 0.482\nMiddle Kingdom & Second Intermediate: F1 = 0.332\nNew Kingdom & Third Intermediate: F1 = 0.752\nLate Period & Greco-Roman Egypt: F1 = 0.650\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nPer-class F1 scores:\nPredynastic & Early Dynastic: F1 = 0.573\nOld Kingdom & First Intermediate: F1 = 0.479\nMiddle Kingdom & Second Intermediate: F1 = 0.330\nNew Kingdom & Third Intermediate: F1 = 0.732\nLate Period & Greco-Roman Egypt: F1 = 0.662\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nPer-class F1 scores:\nPredynastic & Early Dynastic: F1 = 0.578\nOld Kingdom & First Intermediate: F1 = 0.501\nMiddle Kingdom & Second Intermediate: F1 = 0.368\nNew Kingdom & Third Intermediate: F1 = 0.740\nLate Period & Greco-Roman Egypt: F1 = 0.664\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nPer-class F1 scores:\nPredynastic & Early Dynastic: F1 = 0.582\nOld Kingdom & First Intermediate: F1 = 0.493\nMiddle Kingdom & Second Intermediate: F1 = 0.289\nNew Kingdom & Third Intermediate: F1 = 0.699\nLate Period & Greco-Roman Egypt: F1 = 0.630\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nPer-class F1 scores:\nPredynastic & Early Dynastic: F1 = 0.588\nOld Kingdom & First Intermediate: F1 = 0.469\nMiddle Kingdom & Second Intermediate: F1 = 0.302\nNew Kingdom & Third Intermediate: F1 = 0.752\nLate Period & Greco-Roman Egypt: F1 = 0.667\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nPer-class F1 scores:\nPredynastic & Early Dynastic: F1 = 0.587\nOld Kingdom & First Intermediate: F1 = 0.473\nMiddle Kingdom & Second Intermediate: F1 = 0.377\nNew Kingdom & Third Intermediate: F1 = 0.745\nLate Period & Greco-Roman Egypt: F1 = 0.660\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nPer-class F1 scores:\nPredynastic & Early Dynastic: F1 = 0.585\nOld Kingdom & First Intermediate: F1 = 0.479\nMiddle Kingdom & Second Intermediate: F1 = 0.316\nNew Kingdom & Third Intermediate: F1 = 0.751\nLate Period & Greco-Roman Egypt: F1 = 0.664\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nPer-class F1 scores:\nPredynastic & Early Dynastic: F1 = 0.590\nOld Kingdom & First Intermediate: F1 = 0.481\nMiddle Kingdom & Second Intermediate: F1 = 0.319\nNew Kingdom & Third Intermediate: F1 = 0.753\nLate Period & Greco-Roman Egypt: F1 = 0.661\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"\nPer-class F1 scores:\nPredynastic & Early Dynastic: F1 = 0.588\nOld Kingdom & First Intermediate: F1 = 0.479\nMiddle Kingdom & Second Intermediate: F1 = 0.308\nNew Kingdom & Third Intermediate: F1 = 0.748\nLate Period & Greco-Roman Egypt: F1 = 0.664\n","output_type":"stream"},{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1870, training_loss=1.4621599003592916, metrics={'train_runtime': 1657.6925, 'train_samples_per_second': 143.627, 'train_steps_per_second': 1.128, 'total_flos': 2.2187205079291656e+16, 'train_loss': 1.4621599003592916, 'epoch': 10.0})"},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"print(f\"Best model checkpoint: {trainer2.state.best_model_checkpoint}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T12:07:55.142401Z","iopub.execute_input":"2025-05-07T12:07:55.143336Z","iopub.status.idle":"2025-05-07T12:07:55.147449Z","shell.execute_reply.started":"2025-05-07T12:07:55.143309Z","shell.execute_reply":"2025-05-07T12:07:55.146726Z"}},"outputs":[{"name":"stdout","text":"Best model checkpoint: roberta-aeTranslit-classifier_optimized-unbalanced/checkpoint-748\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"# Define save directory\nimport os\nsave_dir = \"/kaggle/working/roberta-aegyptustranslit-classifier-unbalanced-weighted\"\nos.makedirs(save_dir, exist_ok=True)\n\n# Save model (will be pytorch_model.bin)\ntrainer2.save_model(save_dir)\ntokenizer.save_pretrained(save_dir)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T12:07:59.316771Z","iopub.execute_input":"2025-05-07T12:07:59.317377Z","iopub.status.idle":"2025-05-07T12:08:00.621934Z","shell.execute_reply.started":"2025-05-07T12:07:59.317352Z","shell.execute_reply":"2025-05-07T12:08:00.621204Z"}},"outputs":[{"execution_count":44,"output_type":"execute_result","data":{"text/plain":"('/kaggle/working/roberta-aegyptustranslit-classifier-unbalanced-weighted/tokenizer_config.json',\n '/kaggle/working/roberta-aegyptustranslit-classifier-unbalanced-weighted/special_tokens_map.json',\n '/kaggle/working/roberta-aegyptustranslit-classifier-unbalanced-weighted/vocab.json',\n '/kaggle/working/roberta-aegyptustranslit-classifier-unbalanced-weighted/merges.txt',\n '/kaggle/working/roberta-aegyptustranslit-classifier-unbalanced-weighted/added_tokens.json',\n '/kaggle/working/roberta-aegyptustranslit-classifier-unbalanced-weighted/tokenizer.json')"},"metadata":{}}],"execution_count":44},{"cell_type":"code","source":"uwclassifier = pipeline(\"text-classification\", model=\"/kaggle/working/roberta-aegyptustranslit-classifier-unbalanced-weighted\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T12:08:13.742184Z","iopub.execute_input":"2025-05-07T12:08:13.742481Z","iopub.status.idle":"2025-05-07T12:08:14.140655Z","shell.execute_reply.started":"2025-05-07T12:08:13.742459Z","shell.execute_reply":"2025-05-07T12:08:14.139997Z"}},"outputs":[{"name":"stderr","text":"Device set to use cuda:0\n","output_type":"stream"}],"execution_count":45},{"cell_type":"code","source":"copy_btest_df2 = btest_df.drop(columns = [\"preds\",\"period_label_text\"],axis=1)\ncopy_btest_df2.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T12:09:44.379466Z","iopub.execute_input":"2025-05-07T12:09:44.379974Z","iopub.status.idle":"2025-05-07T12:09:44.387849Z","shell.execute_reply.started":"2025-05-07T12:09:44.379939Z","shell.execute_reply":"2025-05-07T12:09:44.387235Z"}},"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"                                   transliteration  period_label\n10687  ꜥnḫ by =s m-bꜣḥ wsꞽr ḫnṱ-ꞽmnṱ nṯr-ꜥꜣ nb-ꞽbt             4\n10688                                         ngꜣy             1\n10689                                   n rḫ =ꞽ st             2\n10690                           nfr-ẖn(.tꞽ)-n-nswt             1\n10691                           ḥtp ꞽb ⸗f ḥr mꜣꜥ.t             3","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>transliteration</th>\n      <th>period_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10687</th>\n      <td>ꜥnḫ by =s m-bꜣḥ wsꞽr ḫnṱ-ꞽmnṱ nṯr-ꜥꜣ nb-ꞽbt</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>10688</th>\n      <td>ngꜣy</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10689</th>\n      <td>n rḫ =ꞽ st</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>10690</th>\n      <td>nfr-ẖn(.tꞽ)-n-nswt</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>10691</th>\n      <td>ḥtp ꞽb ⸗f ḥr mꜣꜥ.t</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":49},{"cell_type":"code","source":"uwpreds = []\nfor cell in copy_btest_df2[\"transliteration\"]:\n    uwpreds.append(uwclassifier(cell)[0]['label'])\n\ncopy_btest_df2[\"preds\"] = uwpreds","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T12:10:30.111169Z","iopub.execute_input":"2025-05-07T12:10:30.111440Z","iopub.status.idle":"2025-05-07T12:10:40.081407Z","shell.execute_reply.started":"2025-05-07T12:10:30.111422Z","shell.execute_reply":"2025-05-07T12:10:40.080688Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"copy_btest_df2['period_label_text'] = copy_btest_df2['period_label'].map(id2label)\n\n# Calculate accuracy\ncorrect_predictions = (copy_btest_df2['period_label_text'] == copy_btest_df2['preds']).sum()\ntotal_predictions = len(copy_btest_df2)\naccuracy = (correct_predictions / total_predictions) * 100\n\n# Display results\nprint(f\"Total samples: {total_predictions}\")\nprint(f\"Correct predictions: {correct_predictions}\")\nprint(f\"Accuracy: {accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T12:10:42.323301Z","iopub.execute_input":"2025-05-07T12:10:42.323584Z","iopub.status.idle":"2025-05-07T12:10:42.330506Z","shell.execute_reply.started":"2025-05-07T12:10:42.323563Z","shell.execute_reply":"2025-05-07T12:10:42.329793Z"}},"outputs":[{"name":"stdout","text":"Total samples: 1188\nCorrect predictions: 680\nAccuracy: 57.24%\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"# Unbalanced test data\ncopy_utest_df2 = utest_df\n\nuwpreds2 = []\nfor cell in copy_utest_df2[\"transliteration\"]:\n    uwpreds2.append(uwclassifier(cell)[0]['label'])\n\ncopy_utest_df2[\"preds\"] = uwpreds2\n\ncopy_utest_df2['period_label_text'] = copy_utest_df2['period_label'].map(id2label)\n\n# Calculate accuracy\ncorrect_predictions = (copy_utest_df2['period_label_text'] == copy_utest_df2['preds']).sum()\ntotal_predictions = len(copy_utest_df2)\naccuracy = (correct_predictions / total_predictions) * 100\n\n# Display results\nprint(f\"Total samples: {total_predictions}\")\nprint(f\"Correct predictions: {correct_predictions}\")\nprint(f\"Accuracy: {accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T12:12:22.242423Z","iopub.execute_input":"2025-05-07T12:12:22.242709Z","iopub.status.idle":"2025-05-07T12:12:47.547133Z","shell.execute_reply.started":"2025-05-07T12:12:22.242687Z","shell.execute_reply":"2025-05-07T12:12:47.546147Z"}},"outputs":[{"name":"stdout","text":"Total samples: 2977\nCorrect predictions: 1614\nAccuracy: 54.22%\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}